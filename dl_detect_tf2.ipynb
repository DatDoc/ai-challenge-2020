{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "dl_detect_tf2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rOvvWAVTkMR7"
      },
      "source": [
        "# Lời giải cơ bản cho cuộc thi\n",
        "\n",
        "Đây là hướng dẫn một phương pháp cơ bản dùng để phát hiện hướng di chuyển (MOI) của phương tiện giao thông trong vùng trong vùng quan sát (ROI) cùng thời điểm phương tiện rời khỏi ROI.\n",
        "\n",
        "Hướng dẫn này sử dụng các mã nguồn mở từ các nguồn sau:\n",
        "\n",
        "* [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)\n",
        "\n",
        "* [Simple online and realtime tracking](https://github.com/abewley/sort)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Tổng quan phương pháp cơ bản được trình bày như sau:\n",
        "* **Phát hiện phương tiện giao thông trong từng frame của video**: Sử dụng TensorFlow Object Detection API. Kết quả trả về là một danh sách các bounding box ứng với tất cả các phương tiện giao thông trong ảnh.\n",
        "* **Theo vết (multiple objects tracking)**: Dựa vào IOU (chỉ số đo đạc mức độ trùng lắp của hai bounding box), các bounding box ở các frame liên tiếp sẽ được gom nhóm và từ đó sẽ hình thành quỹ đạo di chuyển của chính phương tiện đó.\n",
        "* **Xác định hướng di chuyển (MOI) dựa trên quỹ đạo**: MOI của phương tiện sẽ được lựa chọn dựa trên độ tương đồng (ở đây sử dụng Cosine Similarity Score) giữa quỹ đạo của mỗi phương tiện và các MOI sẽ được tính toán.   \n",
        "\n",
        "**Lưu ý**: Trong lời giải cơ bản này, chỉ minh họa việc phát hiện và đếm phương tiện xe máy. Bạn cần chỉnh sửa và cải tiến để có thể đếm được tất cả phương tiện giao thông mà đề bài yêu cầu.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "## Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LBZ9VWZZFUCT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "outputId": "551fc28e-4957-4d37-9ef8-63693d679ed5"
      },
      "source": [
        "!pip install -U --pre tensorflow==\"2.2.0\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow==2.2.0 in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.12.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.30.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.2.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (49.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4YF0EnPMVFA",
        "colab_type": "text"
      },
      "source": [
        "# Cấu hình thư mục lưu trữ dữ liệu\n",
        "\n",
        "Hướng dẫn này được chạy trên [Google Colab](https://colab.research.google.com/) (xem phần [Colab FAQ](https://research.google.com/colaboratory/faq.html) để biết thêm thông tin cần lưu ý)\n",
        "\n",
        "Đoạn chương trình sau cấu hình đường dẫn thư mục Google Drive của bạn để thuận tiện cho việc chạy thí nghiệm nhiều lần và lưu trữ dữ liệu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hynjRVJp4rC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "503875af-c93e-492f-b2a7-c1e3a3c48326"
      },
      "source": [
        "\n",
        "# Mount \"My Drive\" into /content/drive\n",
        "from google.colab import drive\n",
        "\n",
        "google_drive_dir = 'Shared/HCMCAIC'  # @param\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "mount_point = '/content/drive/My Drive/{}'.format(google_drive_dir)\n",
        "\n",
        "# Change the root directory to your mount_point\n",
        "% cd '$mount_point'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Shared/JVN_HCMCAIC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogDEF-0I_mCv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oi28cqGGFWnY",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the baseline repository \n",
        "if not pathlib.Path('ai-challenge-baseline').exists():\n",
        "  ! git clone https://github.com/hcmcaic/ai-challenge-baseline\n",
        "\n",
        "# \n",
        "% cd ai-challenge-baseline\n",
        "\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NwdsBdGhFanc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6747ce0e-9027-456f-982b-8e912830984b"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/drive/My Drive/Shared/JVN_HCMCAIC/models/research\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.0.5)\n",
            "Collecting tf-models-official\n",
            "  Downloading https://files.pythonhosted.org/packages/77/74/14ec628a5be6ef83b95aaddbbc2d19277fb8d3d497188b615ac1377d1bfc/tf_models_official-2.2.1-py2.py3-none-any.whl (711kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.18.5)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (49.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.1.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.3.0)\n",
            "Collecting mlperf-compliance==0.0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/f4/08/f2febd8cbd5c9371f7dab311e90400d83238447ba7609b3bf0145b4cb2a2/mlperf_compliance-0.0.10-py3-none-any.whl\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.6)\n",
            "Collecting tensorflow-model-optimization>=0.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/09/7e/e94aa029999ec30951e8129fa992fecbbaffda66eba97c65d5a83f8ea96d/tensorflow_model_optimization-0.3.0-py2.py3-none-any.whl (165kB)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading https://files.pythonhosted.org/packages/17/e4/a98a3c3098ea55b6ae193a1cd19a221dc3c1bde87a36db5550addc879d36/opencv_python_headless-4.3.0.36-cp36-cp36m-manylinux2014_x86_64.whl (36.4MB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (3.13)\n",
            "Collecting typing==3.7.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/2e/b480ee1b75e6d17d2993738670e75c1feeb9ff7f64452153cf018051cc92/typing-3.7.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: oauth2client>=4.1.2 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.1.3)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/f5/8e6e85ce2e9f6e05040cf0d4e26f43a4718bcc4bce988b433276d4b1a5c1/py-cpuinfo-7.0.0.tar.gz (95kB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.7)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.3.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (3.12.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.22.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (19.3.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (2020.6.20)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Collecting dm-tree~=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/16/48/10fb721334810081b7e6eebeba0d12e12126c76993e8c243062d2f56a89f/dm_tree-0.1.5-cp36-cp36m-manylinux1_x86_64.whl (294kB)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-official->object-detection==0.1) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-official->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-official->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-official->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.17.2)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (2.2.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.30.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.34.2)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->tf-models-official->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1539742 sha256=6c05d744e9346988c044a856597d7e5b9cd8a112ff7d20636c01b6a474a68045\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ob2u5iy9/wheels/c0/ff/b6/ea03bf9637ee4c4dd2e4c0514ffaa2bfb29ac3455200753cf5\n",
            "  Building wheel for py-cpuinfo (setup.py): started\n",
            "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-cp36-none-any.whl size=20069 sha256=efd18571d12c1de4f80a96c8ff609d55a1b330580ce32aa1af3b9dd6151c7726\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/93/7b/127daf0c3a5a49feb2fecd468d508067c733fba5192f726ad1\n",
            "Successfully built object-detection py-cpuinfo\n",
            "Installing collected packages: tf-slim, mlperf-compliance, dm-tree, tensorflow-model-optimization, opencv-python-headless, typing, py-cpuinfo, sentencepiece, tf-models-official, object-detection\n",
            "Successfully installed dm-tree-0.1.5 mlperf-compliance-0.0.10 object-detection-0.1 opencv-python-headless-4.3.0.36 py-cpuinfo-7.0.0 sentencepiece-0.1.91 tensorflow-model-optimization-0.3.0 tf-models-official-2.2.1 tf-slim-1.1.0 typing-3.7.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5aLuBmiZqyq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "2246d062-46a0-4a63-9cff-988e805998d9"
      },
      "source": [
        "# Install the requirements package for SORT source code\n",
        "! pip install filterpy scikit-image lap"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting filterpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/ac8914360460fafa1990890259b7fa5ef7ba4cd59014e782e4ab3ab144d8/filterpy-1.4.5.zip (177kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n",
            "Collecting lap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 15.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from filterpy) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from filterpy) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from filterpy) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->filterpy) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->filterpy) (1.15.0)\n",
            "Building wheels for collected packages: filterpy, lap\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-cp36-none-any.whl size=110451 sha256=2ca9f0861f0cc3b550567db6c04eea15a8b8ea3df7ba15a9bb11506aad6a6b59\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/0c/dd/e92392c3f38a41371602d99fc77d6c1d42aadbf0c6afccdd02\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp36-cp36m-linux_x86_64.whl size=1589006 sha256=e8c96bff43f70a30a53eeec3860892d32b03f03b5b3f489c76b91bf4eaaad15f\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/3e/af/eddcd6ffaa27df8d0ddac573758f8953c4e57c64c4c8c8b7d0\n",
            "Successfully built filterpy lap\n",
            "Installing collected packages: filterpy, lap\n",
            "Successfully installed filterpy-1.4.5 lap-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LT09Kh83xRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gkBIEc_Ri1I",
        "colab_type": "text"
      },
      "source": [
        "# Đọc dữ liệu từ video\n",
        "\n",
        "Đoạn chương trình dưới đây dùng để trích xuất tất cả các khung ảnh (frame) của video và lưu lại dưới dạng các ảnh riêng lẻ trong thư mục tạm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgYcoc4sBEx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "#@markdown Your videos is stored in: \n",
        "\n",
        "input_dir = 'data/videos'\n",
        "\n",
        "#@markdown  Frames extracted from videos will be stored in:\n",
        "output_dir = 'data/frames'  \n",
        "\n",
        "\n",
        "video_paths = []\n",
        "for r, d, f in os.walk(input_dir):\n",
        "    for file in f:\n",
        "        if '.mp4' in file:\n",
        "            video_paths.append(os.path.join(r, file))\n",
        "\n",
        "\n",
        "for video_path in video_paths:\n",
        "    print(video_path)\n",
        "\n",
        "\n",
        "\n",
        "for video_path in video_paths:\n",
        "    video_dir_path = os.path.join(output_dir, os.path.splitext(os.path.basename(video_path))[0])\n",
        "    if not os.path.isdir(video_dir_path):\n",
        "        os.makedirs(video_dir_path)\n",
        "\n",
        "    vid_cap = cv2.VideoCapture(video_path)\n",
        "    num_frms, original_fps = int(vid_cap.get(cv2.CAP_PROP_FRAME_COUNT)), vid_cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "## Number of skip frames\n",
        "    time_stride = 1\n",
        "\n",
        "    for frm_id in tqdm(range(0, num_frms, time_stride)):\n",
        "        vid_cap.set(cv2.CAP_PROP_POS_FRAMES, frm_id)\n",
        "        _, im = vid_cap.read()\n",
        "\n",
        "        cv2.imwrite(os.path.join(video_dir_path, str(frm_id) + '.jpg'), im)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY4a6D4I3xRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def get_keypoint_tuples(eval_config):\n",
        "  \"\"\"Return a tuple list of keypoint edges from the eval config.\n",
        "  \n",
        "  Args:\n",
        "    eval_config: an eval config containing the keypoint edges\n",
        "  \n",
        "  Returns:\n",
        "    a list of edge tuples, each in the format (start, end)\n",
        "  \"\"\"\n",
        "  tuple_list = []\n",
        "  kp_list = eval_config.keypoint_edge\n",
        "  for edge in kp_list:\n",
        "    tuple_list.append((edge.start, edge.end))\n",
        "  return tuple_list\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrTxugQ23xRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_zoo_list(model_zoo_file):\n",
        "    \"\"\"Return a dictionary of model with config and pretrained weight.\n",
        "\n",
        "    Args:\n",
        "      eval_config: an eval config containing the keypoint edges\n",
        "\n",
        "    Returns:\n",
        "      a dict of tuples, each in the format model_name:(config_file, pretrained_weight_link)\n",
        "    \"\"\"\n",
        "    model_zoo_dict = dict()\n",
        "    with open(model_zoo_file) as csvfile:\n",
        "        model_reader = csv.reader(csvfile, delimiter=',')\n",
        "        for row in model_reader:\n",
        "            model_zoo_dict[row[0]] = (row[1], row[2])\n",
        "    \n",
        "    return model_zoo_dict\n",
        "            \n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BqBoTTu3xRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1e5622b-a42e-4941-ecbb-c778b2cc32bb"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_512x512_coco17_tpu-8.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLSqXV_U3xR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def get_keypoint_tuples(eval_config):\n",
        "  \"\"\"Return a tuple list of keypoint edges from the eval config.\n",
        "  \n",
        "  Args:\n",
        "    eval_config: an eval config containing the keypoint edges\n",
        "  \n",
        "  Returns:\n",
        "    a list of edge tuples, each in the format (start, end)\n",
        "  \"\"\"\n",
        "  tuple_list = []\n",
        "  kp_list = eval_config.keypoint_edge\n",
        "  for edge in kp_list:\n",
        "    tuple_list.append((edge.start, edge.end))\n",
        "  return tuple_list\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZCF5UoQJJbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGqOfyODJKxn",
        "colab_type": "text"
      },
      "source": [
        "# Chuẩn bị model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKzgcA_2JkuB",
        "colab_type": "text"
      },
      "source": [
        "Đoạn chương trình sau sử dụng Detection API có sẵn, bạn có thể lựa chọn hoặc thay đổi các detection architecture cùng với backbone mà model zoo cung cấp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49wKV7ExjcUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_zoo_dict = get_model_zoo_list('model_zoo.txt')\n",
        "model_name = 'CenterNet HourGlass104 512x512'\n",
        "model_config_file, model_weight_file = model_zoo_dict[model_name]\n",
        "model_weight_link = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + model_weight_file"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv1KH_opJ4pU",
        "colab_type": "text"
      },
      "source": [
        "Tải và giải nén pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc0mP-E83xR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "6c0a7aa8-5922-4293-9d2a-54fbb6010fb1"
      },
      "source": [
        "!wget $model_weight_link\n",
        "!tar -xf $model_weight_file"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-27 05:34:47--  http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_512x512_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.214.128, 2607:f8b0:4001:c15::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.214.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1426100886 (1.3G) [application/x-tar]\n",
            "Saving to: ‘centernet_hg104_512x512_coco17_tpu-8.tar.gz.2’\n",
            "\n",
            "centernet_hg104_512 100%[===================>]   1.33G  56.2MB/s    in 25s     \n",
            "\n",
            "2020-07-27 05:35:12 (54.6 MB/s) - ‘centernet_hg104_512x512_coco17_tpu-8.tar.gz.2’ saved [1426100886/1426100886]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBvqoYio3xSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline_config = os.path.join('models/research/object_detection/configs/tf2/', model_config_file)\n",
        "model_dir = model_weight_file[:-7] + '/checkpoint'\n",
        "\n",
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(\n",
        "      model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "      model=detection_model)\n",
        "ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()\n",
        "\n",
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "  @tf.function\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn\n",
        "\n",
        "detect_fn = get_model_detection_function(detection_model)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfH54nZw3xSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map_path = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map,\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "    use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLoAfCIZ3xSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dir = output_dir + '/sample_01'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xJ-g4FSUx1l",
        "colab_type": "text"
      },
      "source": [
        "# Lấy thông tin MOI và ROI từ json\n",
        "Đọc file json ứng với mỗi video chứa thông tin ROI và MOI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ile9zBpn3xSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "def load_zone_anno(json_filename):\n",
        "  \"\"\"\n",
        "  Load the json with ROI and MOI annotation.\n",
        "\n",
        "  \"\"\"\n",
        "  with open(json_filename) as jsonfile:\n",
        "    dd = json.load(jsonfile)\n",
        "    polygon = [(int(x), int(y)) for x, y in dd['shapes'][0]['points']]\n",
        "    paths = {}\n",
        "    for it in dd['shapes'][1:]:\n",
        "      kk = str(int(it['label'][-2:]))\n",
        "      paths[kk] = [(int(x), int(y)) for x, y\n",
        "              in it['points']]\n",
        "  return polygon, paths\n",
        "  "
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uttgiFRY3xSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "polygon, paths = load_zone_anno('data/videos/sample_01.json')\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hc3s7VfUAhl",
        "colab_type": "text"
      },
      "source": [
        "# Phát hiện hướng duy chuyển của các xe máy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0tEGNvVP3Ab",
        "colab_type": "text"
      },
      "source": [
        "Trong hướng dẫn này chỉ đếm một loại phương tiện là xe máy. Đối với source code hiện tại, mỗi loại phương tiện cần tạo một tracker khác nhau."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciSftBRfUrsj",
        "colab_type": "text"
      },
      "source": [
        "Hàm kiểm tra phương tiện phát hiện được có nằm trong ROI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6DEp8DV3xSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bb_polygon\n",
        "def check_bbox_intersect_polygon(polygon, bbox):\n",
        "  \"\"\"\n",
        "  \n",
        "  Args:\n",
        "    polygon: List of points (x,y)\n",
        "    bbox: A tuple (xmin, ymin, xmax, ymax)\n",
        "  \n",
        "  Returns:\n",
        "    True if the bbox intersect the polygon\n",
        "  \"\"\"\n",
        "  x1, y1, x2, y2 = bbox\n",
        "  bb = [(x1,y1), (x2, y1), (x2,y2), (x1,y2)]\n",
        "  return bb_polygon.is_bounding_box_intersect(bb, polygon)\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2uKQUur3xSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sort import *\n",
        "moto_tracker = Sort()\n",
        "truck_tracker = Sort()\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuWlt2S03xSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an motobikes tracker with default parameter.\n",
        "# Please read the sort documentation for the custom paramenters.\n",
        "\n",
        "moto_tracker = Sort()\n",
        "\n",
        "# If you want to track another vehicle class, you need to declare a new tracker.\n",
        "# truck_tracker = Sort()\n",
        "\n",
        "track_dict = {}\n",
        "\n",
        "N_FRAMES = 20\n",
        "\n",
        "for frame_id in range(1, N_FRAMES):\n",
        "  image_path = os.path.join(image_dir, '{}.jpg'.format(frame_id))\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "\n",
        "  im_width, im_height, _ = image_np.shape\n",
        "  input_tensor = tf.convert_to_tensor(\n",
        "      np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "  detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "\n",
        "  boxes = detections['detection_boxes'][0]\n",
        "  scores = detections['detection_scores'][0]\n",
        "  classes = detections['detection_classes'][0]\n",
        "\n",
        "\n",
        "  dets = []\n",
        "  for bb, s, c in zip(boxes, scores, classes):\n",
        "    ymin, xmin, ymax, xmax = bb.numpy()\n",
        "    xmin, ymin, xmax, ymax = xmin*im_width, ymin*im_height, xmax*im_width, ymax*im_height\n",
        "    if check_bbox_intersect_polygon(polygon, (xmin, ymin, xmax, ymax)):\n",
        "      # check if the bbox is in ROI\n",
        "      dets.append((frame_id, c.numpy(), xmin, ymin, xmax, ymax, s.numpy()))\n",
        "\n",
        "\n",
        "  label_id_offset = 1\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "\n",
        "  dets = np.array(dets)\n",
        "\n",
        "  # Only get the detections with the class label is '3' which indicate the motobike class.\n",
        "  moto_dets = dets[dets[:,1]==3]\n",
        "  moto_dets = np.array(moto_dets)\n",
        "\n",
        "  trackers = moto_tracker.update(moto_dets)\n",
        "  for xmin, ymin, xmax, ymax, track_id in trackers:\n",
        "    track_id = int(track_id)\n",
        "    # print(track_id)\n",
        "    if track_id not in track_dict.keys():\n",
        "      track_dict[track_id] = [(xmin, ymin, xmax, ymax, frame_id)]\n",
        "    else:\n",
        "      track_dict[track_id].append((xmin, ymin, xmax, ymax, frame_id))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJibvnHA3xSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# moto_vector_list: list of tuples (first_point, last_point, last_frame_id)\n",
        "# list of moto movement vector and the last frame_id when it is still in the ROI.\n",
        "\n",
        "moto_vector_list = []\n",
        "for tracker_id, tracker_list in track_dict.items():\n",
        "  if len(tracker_list) > 1:\n",
        "    first = tracker_list[0]\n",
        "    last = tracker_list[-1]\n",
        "    first_point = ((first[2] - first[0])/2, (first[3] - first[1])/2)\n",
        "    last_point = ((last[2] - last[0])/2, (last[3] - last[1])/2)\n",
        "    moto_vector_list.append((first_point, last_point, last[4]))\n",
        "    \n",
        "    "
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Foy99tKg3xSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosin_similarity(a2d, b2d):\n",
        "  \n",
        "  a = np.array((a2d[1][0] - a2d[0][0], a2d[1][1 ]- a2d[0][1]))\n",
        "  b = np.array((b2d[1][0] - b2d[0][1], b2d[1][1] - b2d[1][0]))\n",
        "  return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c576pYuNaQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MOTO_CLASS_ID = 1"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCjVR7a9TxaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Đếm số lương\n",
        " "
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLkDtcLPT4Uk",
        "colab_type": "text"
      },
      "source": [
        "Phát hiện MOI tương ứng với mỗi xe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-Q9yaFbq3xSv"
      },
      "outputs": [],
      "source": [
        "def counting_moi(paths, moto_vector_list):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    paths: List of MOI - (first_point, last_point)\n",
        "    moto_vector_list: List of tuples (first_point, last_point, last_frame_id) \n",
        "  \n",
        "  Returns:\n",
        "    A list of tuples (frame_id, movement_id, vehicle_class_id)\n",
        "  \"\"\"\n",
        "  moi_detection_list = []\n",
        "  for moto_vector in moto_vector_list:\n",
        "    max_cosin = -2\n",
        "    movement_id = ''\n",
        "    last_frame = 0\n",
        "    for movement_label, movement_vector in paths.items():\n",
        "      cosin = cosin_similarity(movement_vector, moto_vector)\n",
        "      if cosin > max_cosin:\n",
        "        max_cosin = cosin\n",
        "        movement_id = movement_label\n",
        "        last_frame = moto_vector[2]\n",
        "\n",
        "    moi_detection_list.append((last_frame, movement_id, MOTO_CLASS_ID))\n",
        "  return moi_detection_list\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uPXjMdpJFDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "moto_moi_detections = counting_moi(paths, moto_vector_list)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xsPexKFEssj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a5dbdb6-82ae-4ffb-be8d-90e679206825"
      },
      "source": [
        "print(moto_moi_detections)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(2, '1', 1), (19, '1', 1), (19, '2', 1), (19, '2', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Xuất kết quả theo định dạng nộp\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS16AQoA3xS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "result_filename = 'result.txt'\n",
        "video_id = '000'\n",
        "with open(result_filename, 'w') as result_file:\n",
        "  for frame_id, movement_id, vehicle_class_id in moto_moi_detections:\n",
        "    result_file.write('{} {} {} {}\\n'.format(video_id, frame_id, movement_id, vehicle_class_id))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}